{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5052"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load prepared data\n",
    "import pandas as pd\n",
    "r = pd.read_csv('result.csv', encoding='utf8')\n",
    "r = r[r['Answer']!='not']\n",
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tokenize_uk import *\n",
    "import os,sys\n",
    "mitie_path = os.environ['MITIE_HOME']\n",
    "sys.path.append(mitie_path)\n",
    "\n",
    "from mitie import *\n",
    "import itertools\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load previous models\n",
    "ner = named_entity_extractor(\"uk_model.dat\")\n",
    "trainer = binary_relation_detector_trainer(\"people.person.parents\", ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Objects</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Ярополк, жив, у, згоді, з, батьком, Володимир...</td>\n",
       "      <td>[11, 12]</td>\n",
       "      <td>[6, 7]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Після, смерті, Ріцімера, Східна, Римська, імп...</td>\n",
       "      <td>[34, 35]</td>\n",
       "      <td>[27, 28]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Був, сином, Сапа, Інки, Уайни, Капака, та, мо...</td>\n",
       "      <td>[26]</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Володимир, Ярославич, —, князь, Новгородський...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[9, 10, 11]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Відповідно, до, напису, біля, входу, до, прим...</td>\n",
       "      <td>[30, 31]</td>\n",
       "      <td>[24, 25]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Subjects      Objects  \\\n",
       "0  [Ярополк, жив, у, згоді, з, батьком, Володимир...  [11, 12]       [6, 7]   \n",
       "1  [Після, смерті, Ріцімера, Східна, Римська, імп...  [34, 35]     [27, 28]   \n",
       "2  [Був, сином, Сапа, Інки, Уайни, Капака, та, мо...      [26]       [4, 5]   \n",
       "3  [Володимир, Ярославич, —, князь, Новгородський...    [0, 1]  [9, 10, 11]   \n",
       "4  [Відповідно, до, напису, біля, входу, до, прим...  [30, 31]     [24, 25]   \n",
       "\n",
       "   Answer  \n",
       "0       1  \n",
       "1       1  \n",
       "2       0  \n",
       "3       1  \n",
       "4       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize texts and find anchors\n",
    "def detect_anchor(tokens, anchor):\n",
    "    found = False\n",
    "    index = 0\n",
    "    for i in range(len(tokens)):\n",
    "        token = tokens[i]\n",
    "        pattern = re.escape(anchor[index]) + u\"[а|ом]?\"\n",
    "        match = re.match(pattern, token, flags=re.U|re.L)\n",
    "        \n",
    "        if(found):\n",
    "            if(match is not None):\n",
    "                index += 1\n",
    "            else:\n",
    "                index = 0\n",
    "                found = False\n",
    "                pattern = re.escape(anchor[index]) + u\"[а|ом]?\"\n",
    "                match = re.match(pattern, token, flags=re.U|re.L)\n",
    "        \n",
    "        if(not found and match is not None):\n",
    "            start = i\n",
    "            index += 1\n",
    "            found = True\n",
    "            \n",
    "        if(index == len(anchor)):\n",
    "            end = i + 1\n",
    "            yield range(start, end)\n",
    "            index = 0\n",
    "            found = False\n",
    "            \n",
    "def extract_from_tokens_by_range(tokens, r):\n",
    "    return ' '.join(tokens[r[0]:r[-1]+1])\n",
    "\n",
    "def convert_answer(answer):\n",
    "    if(answer=='has' or answer=='weak'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "def no_range_overlaps(r1, r2):\n",
    "    return max(r1) < min(r2) or max(r2) < min(r1)\n",
    "    \n",
    "\n",
    "def select_closest(detection1, detection2):\n",
    "    min_distance = 1000\n",
    "    min_pair = ([],[])\n",
    "    for d1 in detection1:\n",
    "        for d2 in detection2:\n",
    "            if not no_range_overlaps(d1, d2): continue\n",
    "            if max(d1) < min(d2):\n",
    "                distance = min(d2)-max(d1)\n",
    "            else:\n",
    "                distance = min(d1)-max(d2)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                min_pair = (d1,d2)\n",
    "                \n",
    "    return min_pair\n",
    "    \n",
    "def prepare_row(row, only_closest_anchors=True, verbose=False):\n",
    "    text = row['Text']\n",
    "    if(verbose):\n",
    "        print text\n",
    "    tokens = tokenize_text(text)\n",
    "    tokens = [t for tt in tokens for sentence in tt for t in sentence]\n",
    "    detection1 = list(detect_anchor(tokens, tokenize_words(row['SubjectAnchor'])))\n",
    "    if(verbose):\n",
    "        for d in detection1:\n",
    "            print extract_from_tokens_by_range(tokens, d)\n",
    "    detection2 = list(detect_anchor(tokens, tokenize_words(row['ObjectAnchor'])))\n",
    "    if(verbose):\n",
    "        for d in detection2:\n",
    "            print extract_from_tokens_by_range(tokens, d)\n",
    "    \n",
    "    if only_closest_anchors:\n",
    "        detection1, detection2 = select_closest(detection1, detection2)\n",
    "            \n",
    "    return (tokens, detection1, detection2, convert_answer(row['Answer']))\n",
    "\n",
    "df = pd.DataFrame(list(r.apply(prepare_row,axis=1)), columns=['Text','Subjects','Objects','Answer'])\n",
    "correct = df.apply(lambda row: len(row['Subjects']) > 0 and len(row['Objects']) > 0, axis=1)\n",
    "df = df[correct]\n",
    "no_overlap = df.apply(lambda row: no_range_overlaps(row['Subjects'], row['Objects']), axis=1)\n",
    "df = df[no_overlap]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5052"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get train-test split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = df[['Subjects', 'Objects']]\n",
    "y = df['Answer']\n",
    "\n",
    "state = 42\n",
    "sss = StratifiedKFold(n_splits=4, shuffle=True, random_state=state).split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# mitie trainig function\n",
    "def train_mitie_model(X, y, train_index):\n",
    "    for i in train_index:\n",
    "        subject_position = X.iloc[i]['Subjects']\n",
    "        object_position = X.iloc[i]['Objects']\n",
    "        text = X.iloc[i]['Text']\n",
    "\n",
    "        if(y.iloc[i]==1):\n",
    "            trainer.add_positive_binary_relation(text, subject_position, object_position)\n",
    "            trainer.add_negative_binary_relation(text, object_position, subject_position)\n",
    "        else:\n",
    "            trainer.add_negative_binary_relation(text, subject_position, object_position)\n",
    "    return trainer.train()\n",
    "\n",
    "\n",
    "def mitie_predict(model, text, subj, obj):\n",
    "    rel = ner.extract_binary_relation(text, subj, obj)\n",
    "    return model(rel)\n",
    "\n",
    "def train_logreg_model(mitie_model, X, y, train_index):\n",
    "    logreg_x = X.iloc[train_index].apply(lambda row: mitie_predict(mitie_model, row['Text'], row['Subjects'], row['Objects']), axis=1)\n",
    "    model = LogisticRegression(random_state=state, fit_intercept=False, penalty='l1')\n",
    "    logreg_x = np.array(logreg_x).reshape((len(logreg_x), 1))\n",
    "    logreg_y = np.array(y.iloc[train_index])\n",
    "    model.fit(logreg_x, logreg_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC: 0.817302182875\n",
      "Recall: 0.87417218543\n",
      "Precision: 0.715059588299\n",
      "F1: 0.786650774732\n",
      "--------------------\n",
      "PR AUC: 0.992082033501\n",
      "Recall: 0.886092715232\n",
      "Precision: 1.0\n",
      "F1: 0.939606741573\n",
      "--------------------\n",
      "PR AUC: 0.995080398542\n",
      "Recall: 0.913907284768\n",
      "Precision: 1.0\n",
      "F1: 0.955017301038\n",
      "--------------------\n",
      "PR AUC: 0.997799882386\n",
      "Recall: 0.992052980132\n",
      "Precision: 1.0\n",
      "F1: 0.996010638298\n",
      "--------------------\n",
      "Mean PR AUC: 0.997799882386\n",
      "Mean recall: 0.916556291391\n",
      "Mean precision: 0.928764897075\n",
      "Mean F1: 0.91932136391\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, f1_score, precision_score, average_precision_score\n",
    "\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "y_trues = []\n",
    "y_preds = []\n",
    "y_preds_probas = []\n",
    "pr_aucs = []\n",
    "\n",
    "for train_i, test_i in sss:\n",
    "    \n",
    "    mitie_model = train_mitie_model(df, y, train_i)\n",
    "    logreg_model = train_logreg_model(mitie_model, df, y, train_i)\n",
    "    \n",
    "    logreg_x = df.iloc[test_i].apply(lambda row: mitie_predict(mitie_model, row['Text'], row['Subjects'], row['Objects']), axis=1)\n",
    "    logreg_x = np.array(logreg_x).reshape((len(logreg_x), 1))\n",
    "    \n",
    "    y_pred_proba = logreg_model.predict_proba(logreg_x)[:,1]\n",
    "    #y_pred = logreg_model.predict(logreg_x)\n",
    "    threshold = 0.2\n",
    "    y_pred = map(lambda y: 1.0 if y > threshold else 0.0, y_pred_proba)\n",
    "    y_true = np.array(y.iloc[test_i].astype(float))\n",
    "    \n",
    "    pr_auc = average_precision_score(y_true, y_pred_proba)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print \"PR AUC: \" + str(pr_auc)\n",
    "    print \"Recall: \" + str(recall)\n",
    "    print \"Precision: \" + str(precision)\n",
    "    print \"F1: \" + str(f1)\n",
    "    print \"-\"*20\n",
    "    \n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    pr_aucs.append(pr_auc)\n",
    "    y_trues.append(y_true)\n",
    "    y_preds.append(y_pred)\n",
    "    y_preds_probas.append(y_pred_proba)\n",
    "\n",
    "print \"Mean PR AUC: \" + str(np.mean(pr_auc))\n",
    "print \"Mean recall: \" + str(np.mean(recall_scores))\n",
    "print \"Mean precision: \" + str(np.mean(precision_scores))\n",
    "print \"Mean F1: \" + str(np.mean(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot PR curve\n",
    "# from sklearn.metrics import precision_recall_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# import matplotlib\n",
    "# matplotlib.rcParams['figure.figsize'] = (10,10)\n",
    "# from itertools import cycle\n",
    "\n",
    "# precision, recall, _ = precision_recall_curve(y_trues[0], y_preds[0])\n",
    "\n",
    "# # setup plot details\n",
    "# colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal'])\n",
    "# lw = 2\n",
    "\n",
    "# # Plot Precision-Recall curve\n",
    "# plt.clf()\n",
    "# plt.plot(recall, precision, lw=lw, color='navy',\n",
    "#          label='Precision-Recall curve')\n",
    "# plt.xlabel('Recall')\n",
    "# plt.ylabel('Precision')\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.title('Precision-Recall example: AUC={0:0.2f}'.format(average_precision_score(y_true, y_pred_proba)))\n",
    "# plt.legend(loc=\"lower left\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC: 0.997799882386\n",
      "Recall: 0.992052980132\n",
      "Precision: 1.0\n",
      "F1: 0.996010638298\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.03\n",
    "y_pred_t = map(lambda y: 1.0 if y > threshold else 0.0, y_pred_proba)\n",
    "\n",
    "\n",
    "print \"PR AUC: \" + str(average_precision_score(y_true, y_pred_proba))\n",
    "print \"Recall: \" + str(recall_score(y_true, y_pred_t))\n",
    "print \"Precision: \" + str(precision_score(y_true, y_pred_t))\n",
    "print \"F1: \" + str(f1_score(y_true, y_pred_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_i = df.index\n",
    "mitie_model = train_mitie_model(df, y, train_i)\n",
    "logreg_model = train_logreg_model(mitie_model, df, y, train_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ві́ктор|Ві́кторович|Януко́вич|—|український|політик|,|Народний|депутат|України|5-го|,|6-го|і|7-го|скликань|,|син|колишнього|президента|України|Віктора|Федоровича|Януковича|,|кандидат|наук|з|державного|управління|,|майстер|спорту|в|категорії|автоспорт|,|чемпіон|України|з|трофі|-|рейдів|2011|року|.\n"
     ]
    }
   ],
   "source": [
    "# check with random data\n",
    "sent = u'Ві́ктор Ві́кторович Януко́вич — український політик, Народний депутат України 5-го, 6-го і 7-го скликань, син колишнього президента України Віктора Федоровича Януковича, кандидат наук з державного управління, майстер спорту в категорії автоспорт, чемпіон України з трофі-рейдів 2011 року.'\n",
    "tokens = tokenize_words(sent)\n",
    "print '|'.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6689691843142125"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj = [0,1,2]\n",
    "obj = [21,22,23]\n",
    "mitie_result = mitie_predict(mitie_model, tokens, subj, obj)\n",
    "mitie_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.95804969])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model.predict_proba(np.array([mitie_result]).reshape(-1, 1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0051469])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mitie_result = mitie_predict(mitie_model, tokens, obj, subj)\n",
    "logreg_model.predict_proba(np.array([mitie_result]).reshape(-1, 1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00691019])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = u'У часи перебування на посаді Голови облдержадміністрації Віктор Янукович був лобістом деяких проектів у рамках регіону, зокрема Роман Гайовий з Агентства журналістських досліджень приводить такі успішні лобістські проекти губернатора Януковича: введення високого мита на коксівне вугілля, що дало можливість вирівняти'\n",
    "tokens = tokenize_words(sent)\n",
    "subj = [7]\n",
    "obj = [18,19]\n",
    "mitie_result = mitie_predict(mitie_model, tokens, obj, subj)\n",
    "logreg_model.predict_proba(np.array([mitie_result]).reshape(-1, 1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mitie_model.save_to_disk('people.person.parents.svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('people.person.parents.pkl', 'wb') as f:\n",
    "    pickle.dump(logreg_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
