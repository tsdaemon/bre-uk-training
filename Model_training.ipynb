{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5053"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load prepared data\n",
    "import pandas as pd\n",
    "r = pd.read_csv('result.csv', encoding='utf8')\n",
    "r = r[r['Answer']!='not']\n",
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tokenize_uk import *\n",
    "import os,sys\n",
    "mitie_path = os.environ['MITIE_HOME']\n",
    "sys.path.append(mitie_path)\n",
    "\n",
    "from mitie import *\n",
    "import itertools\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load previous models\n",
    "ner = named_entity_extractor(\"uk_model.dat\")\n",
    "trainer = binary_relation_detector_trainer(\"people.person.parents\", ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Несе', 'Галя', 'воду', ',', 'коромисло', 'гнеться']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenize_words('Несе Галя воду, коромисло гнеться')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(range(1, 2), 'PERS', 0.7061146871904945)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner.extract_entities(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anatoliy\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\__main__.py:8: DeprecationWarning: LOCALE flag with a str pattern is deprecated. Will be an error in 3.6\n",
      "C:\\Users\\Anatoliy\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\__main__.py:17: DeprecationWarning: LOCALE flag with a str pattern is deprecated. Will be an error in 3.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Objects</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Ярополк, жив, у, згоді, з, батьком, Володимир...</td>\n",
       "      <td>(11, 12)</td>\n",
       "      <td>(6, 7)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Після, смерті, Ріцімера, Східна, Римська, імп...</td>\n",
       "      <td>(34, 35)</td>\n",
       "      <td>(27, 28)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Був, сином, Сапа, Інки, Уайни, Капака, та, мо...</td>\n",
       "      <td>(26)</td>\n",
       "      <td>(4, 5)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Володимир, Ярославич, —, князь, Новгородський...</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(9, 10, 11)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Відповідно, до, напису, біля, входу, до, прим...</td>\n",
       "      <td>(30, 31)</td>\n",
       "      <td>(24, 25)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Subjects      Objects  \\\n",
       "0  [Ярополк, жив, у, згоді, з, батьком, Володимир...  (11, 12)       (6, 7)   \n",
       "1  [Після, смерті, Ріцімера, Східна, Римська, імп...  (34, 35)     (27, 28)   \n",
       "2  [Був, сином, Сапа, Інки, Уайни, Капака, та, мо...      (26)       (4, 5)   \n",
       "3  [Володимир, Ярославич, —, князь, Новгородський...    (0, 1)  (9, 10, 11)   \n",
       "4  [Відповідно, до, напису, біля, входу, до, прим...  (30, 31)     (24, 25)   \n",
       "\n",
       "   Answer  \n",
       "0       1  \n",
       "1       1  \n",
       "2       0  \n",
       "3       1  \n",
       "4       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize texts and find anchors\n",
    "def detect_anchor(tokens, anchor):\n",
    "    found = False\n",
    "    index = 0\n",
    "    for i in range(len(tokens)):\n",
    "        token = tokens[i]\n",
    "        pattern = re.escape(anchor[index]) + u\"[а|ом]?\"\n",
    "        match = re.match(pattern, token, flags=re.U|re.L)\n",
    "        \n",
    "        if(found):\n",
    "            if(match is not None):\n",
    "                index += 1\n",
    "            else:\n",
    "                index = 0\n",
    "                found = False\n",
    "                pattern = re.escape(anchor[index]) + u\"[а|ом]?\"\n",
    "                match = re.match(pattern, token, flags=re.U|re.L)\n",
    "        \n",
    "        if(not found and match is not None):\n",
    "            start = i\n",
    "            index += 1\n",
    "            found = True\n",
    "            \n",
    "        if(index == len(anchor)):\n",
    "            end = i + 1\n",
    "            yield range(start, end)\n",
    "            index = 0\n",
    "            found = False\n",
    "            \n",
    "def extract_from_tokens_by_range(tokens, r):\n",
    "    return ' '.join(tokens[r[0]:r[-1]+1])\n",
    "\n",
    "def convert_answer(answer):\n",
    "    if(answer=='has' or answer=='weak'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "def no_range_overlaps(r1, r2):\n",
    "    return max(r1) < min(r2) or max(r2) < min(r1)\n",
    "    \n",
    "\n",
    "def select_closest(detection1, detection2):\n",
    "    min_distance = 1000\n",
    "    min_pair = ([],[])\n",
    "    for d1 in detection1:\n",
    "        for d2 in detection2:\n",
    "            if not no_range_overlaps(d1, d2): continue\n",
    "            if max(d1) < min(d2):\n",
    "                distance = min(d2)-max(d1)\n",
    "            else:\n",
    "                distance = min(d1)-max(d2)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                min_pair = (d1,d2)\n",
    "                \n",
    "    return min_pair\n",
    "    \n",
    "def prepare_row(row, only_closest_anchors=True, verbose=False):\n",
    "    text = row['Text']\n",
    "    if(verbose):\n",
    "        print(text)\n",
    "    tokens = tokenize_text(text)\n",
    "    tokens = [t for tt in tokens for sentence in tt for t in sentence]\n",
    "    detection1 = list(detect_anchor(tokens, tokenize_words(row['SubjectAnchor'])))\n",
    "    if(verbose):\n",
    "        for d in detection1:\n",
    "            print(extract_from_tokens_by_range(tokens, d))\n",
    "    detection2 = list(detect_anchor(tokens, tokenize_words(row['ObjectAnchor'])))\n",
    "    if(verbose):\n",
    "        for d in detection2:\n",
    "            print(extract_from_tokens_by_range(tokens, d))\n",
    "    \n",
    "    if only_closest_anchors:\n",
    "        detection1, detection2 = select_closest(detection1, detection2)\n",
    "            \n",
    "    return (tokens, detection1, detection2, convert_answer(row['Answer']))\n",
    "\n",
    "df = pd.DataFrame(list(r.apply(prepare_row,axis=1)), columns=['Text','Subjects','Objects','Answer'])\n",
    "correct = df.apply(lambda row: len(row['Subjects']) > 0 and len(row['Objects']) > 0, axis=1)\n",
    "df = df[correct]\n",
    "no_overlap = df.apply(lambda row: no_range_overlaps(row['Subjects'], row['Objects']), axis=1)\n",
    "df = df[no_overlap]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5053"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get train-test split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = df[['Subjects', 'Objects']]\n",
    "y = df['Answer']\n",
    "\n",
    "state = 42\n",
    "sss = StratifiedKFold(n_splits=4, shuffle=True, random_state=state).split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# mitie trainig function\n",
    "def train_mitie_model(X, y, train_index):\n",
    "    for i in train_index:\n",
    "        subject_position = X.iloc[i]['Subjects']\n",
    "        object_position = X.iloc[i]['Objects']\n",
    "        text = X.iloc[i]['Text']\n",
    "\n",
    "        if(y.iloc[i]==1):\n",
    "            trainer.add_positive_binary_relation(text, subject_position, object_position)\n",
    "            trainer.add_negative_binary_relation(text, object_position, subject_position)\n",
    "        else:\n",
    "            trainer.add_negative_binary_relation(text, subject_position, object_position)\n",
    "    return trainer.train()\n",
    "\n",
    "\n",
    "def mitie_predict(model, text, subj, obj):\n",
    "    rel = ner.extract_binary_relation(text, subj, obj)\n",
    "    return model(rel)\n",
    "\n",
    "def train_logreg_model(mitie_model, X, y, train_index):\n",
    "    logreg_x = X.iloc[train_index].apply(lambda row: mitie_predict(mitie_model, row['Text'], row['Subjects'], row['Objects']), axis=1)\n",
    "    model = LogisticRegression(random_state=state, fit_intercept=False, penalty='l1')\n",
    "    logreg_x = np.array(logreg_x).reshape((len(logreg_x), 1))\n",
    "    logreg_y = np.array(y.iloc[train_index])\n",
    "    model.fit(logreg_x, logreg_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, f1_score, precision_score, average_precision_score\n",
    "\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "y_trues = []\n",
    "y_preds = []\n",
    "y_preds_probas = []\n",
    "pr_aucs = []\n",
    "\n",
    "for train_i, test_i in sss:\n",
    "    \n",
    "    mitie_model = train_mitie_model(df, y, train_i)\n",
    "    logreg_model = train_logreg_model(mitie_model, df, y, train_i)\n",
    "    \n",
    "    logreg_x = df.iloc[test_i].apply(lambda row: mitie_predict(mitie_model, row['Text'], row['Subjects'], row['Objects']), axis=1)\n",
    "    logreg_x = np.array(logreg_x).reshape((len(logreg_x), 1))\n",
    "    \n",
    "    y_pred_proba = logreg_model.predict_proba(logreg_x)[:,1]\n",
    "    #y_pred = logreg_model.predict(logreg_x)\n",
    "    threshold = 0.2\n",
    "    y_pred = map(lambda y: 1.0 if y > threshold else 0.0, y_pred_proba)\n",
    "    y_true = np.array(y.iloc[test_i].astype(float))\n",
    "    \n",
    "    pr_auc = average_precision_score(y_true, y_pred_proba)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(\"PR AUC: \" + str(pr_auc))\n",
    "    print(\"Recall: \" + str(recall))\n",
    "    print(\"Precision: \" + str(precision))\n",
    "    print(\"F1: \" + str(f1))\n",
    "    print(\"-\"*20)\n",
    "    \n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    pr_aucs.append(pr_auc)\n",
    "    y_trues.append(y_true)\n",
    "    y_preds.append(y_pred)\n",
    "    y_preds_probas.append(y_pred_proba)\n",
    "\n",
    "print(\"Mean PR AUC: \" + str(np.mean(pr_auc)))\n",
    "print(\"Mean recall: \" + str(np.mean(recall_scores)))\n",
    "print(\"Mean precision: \" + str(np.mean(precision_scores)))\n",
    "print(\"Mean F1: \" + str(np.mean(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot PR curve\n",
    "# from sklearn.metrics import precision_recall_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# import matplotlib\n",
    "# matplotlib.rcParams['figure.figsize'] = (10,10)\n",
    "# from itertools import cycle\n",
    "\n",
    "# precision, recall, _ = precision_recall_curve(y_trues[0], y_preds[0])\n",
    "\n",
    "# # setup plot details\n",
    "# colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal'])\n",
    "# lw = 2\n",
    "\n",
    "# # Plot Precision-Recall curve\n",
    "# plt.clf()\n",
    "# plt.plot(recall, precision, lw=lw, color='navy',\n",
    "#          label='Precision-Recall curve')\n",
    "# plt.xlabel('Recall')\n",
    "# plt.ylabel('Precision')\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.title('Precision-Recall example: AUC={0:0.2f}'.format(average_precision_score(y_true, y_pred_proba)))\n",
    "# plt.legend(loc=\"lower left\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threshold = 0.03\n",
    "y_pred_t = map(lambda y: 1.0 if y > threshold else 0.0, y_pred_proba)\n",
    "\n",
    "\n",
    "print(\"PR AUC: \" + str(average_precision_score(y_true, y_pred_proba)))\n",
    "print(\"Recall: \" + str(recall_score(y_true, y_pred_t)))\n",
    "print(\"Precision: \" + str(precision_score(y_true, y_pred_t)))\n",
    "print(\"F1: \" + str(f1_score(y_true, y_pred_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_i = df.index\n",
    "mitie_model = train_mitie_model(df, y, train_i)\n",
    "logreg_model = train_logreg_model(mitie_model, df, y, train_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check with random data\n",
    "sent = u'Ві́ктор Ві́кторович Януко́вич — український політик, Народний депутат України 5-го, 6-го і 7-го скликань, син колишнього президента України Віктора Федоровича Януковича, кандидат наук з державного управління, майстер спорту в категорії автоспорт, чемпіон України з трофі-рейдів 2011 року.'\n",
    "tokens = tokenize_words(sent)\n",
    "print('|'.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subj = [0,1,2]\n",
    "obj = [21,22,23]\n",
    "mitie_result = mitie_predict(mitie_model, tokens, subj, obj)\n",
    "mitie_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg_model.predict_proba(np.array([mitie_result]).reshape(-1, 1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mitie_result = mitie_predict(mitie_model, tokens, obj, subj)\n",
    "logreg_model.predict_proba(np.array([mitie_result]).reshape(-1, 1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent = u'У часи перебування на посаді Голови облдержадміністрації Віктор Янукович був лобістом деяких проектів у рамках регіону, зокрема Роман Гайовий з Агентства журналістських досліджень приводить такі успішні лобістські проекти губернатора Януковича: введення високого мита на коксівне вугілля, що дало можливість вирівняти'\n",
    "tokens = tokenize_words(sent)\n",
    "subj = [7]\n",
    "obj = [18,19]\n",
    "mitie_result = mitie_predict(mitie_model, tokens, obj, subj)\n",
    "logreg_model.predict_proba(np.array([mitie_result]).reshape(-1, 1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mitie_model.save_to_disk('people.person.parents.svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('people.person.parents.pkl', 'wb') as f:\n",
    "    pickle.dump(logreg_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
